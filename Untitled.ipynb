{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "VGG19_LAYERS=(\n",
    "    'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "\n",
    "    'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "\n",
    "    'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "    'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "\n",
    "    'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "    'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "\n",
    "    'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "    'relu5_3', 'conv5_4', 'relu5_4'\n",
    ")\n",
    "\n",
    "def load_net(data_path):\n",
    "    data = scipy.io.loadmat(data_path)\n",
    "    mean = data['normalization'][0][0][0]\n",
    "    mean_pixel = np.mean(mean, axis=(0,1))\n",
    "    weights = data['layers'][0]\n",
    "    return weights, mean_pixel \n",
    "\n",
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "\n",
    "def _pool_layer(input):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "            padding='SAME')\n",
    "\n",
    "def preprocess(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "\n",
    "def unprocess(image, mean_pixel):\n",
    "    return image + mean_pixel\n",
    "\n",
    "def net_preloaded(input_image, weights):\n",
    "    net = {}\n",
    "    current = input_image\n",
    "\n",
    "    for i, name in enumerate(VGG19_LAYERS):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias =  weights[i][0][0][0][0] \n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "\n",
    "            current = _conv_layer(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current)\n",
    "        elif kind == 'pool':\n",
    "            current = _pool_layer(current)\n",
    "        net[name] = current\n",
    "\n",
    "    assert len(net) == len(VGG19_LAYERS)\n",
    "    return net\n",
    "\n",
    "def batch_norm(input):\n",
    "    epsilon = 1e-3\n",
    "    batch_mean,batch_var=tf.nn.moments(input,[0])\n",
    "    normalized=tf.nn.batch_normalization(input,mean=batch_mean,variance=batch_var,offset=None,scale=None,variance_epsilon=epsilon)\n",
    "    return normalized\n",
    "\n",
    "def discrimator(input_image):\n",
    "    path = 'G:\\\\下载\\\\imagenet-vgg-verydeep-19.mat'\n",
    "    weights, mean_pixel = load_net(path)\n",
    "    img = preprocess(input_image, mean_pixel)\n",
    "    img = np.array([img]).astype(np.float32)\n",
    "    \n",
    "    with tf.variable_scope(\"VGG19_LAYERS\"):\n",
    "        relu5_4=net_preloaded(img, weights)['relu5_4']\n",
    "\n",
    "    with tf.variable_scope('FC_Softmax'):\n",
    "        #block6 : [batch, 8, 8, 512] => [batch, 4096]\n",
    "        with tf.variable_scope('FC6') as scope:\n",
    "            shape=int(np.prod(relu5_4.get_shape()[1:]))\n",
    "            weight=tf.Variable(tf.truncated_normal([shape,4096],dtype=tf.float32,stddev=1e-1))\n",
    "            bias=tf.Variable(tf.constant(1.0,shape=[4096],dtype=tf.float32))\n",
    "            flat=tf.reshape(relu5_4,[-1,shape])\n",
    "            fc6=tf.nn.bias_add(tf.matmul(flat,weight),bias)\n",
    "            fc6=tf.nn.relu(fc6) \n",
    "            fc6=batch_norm(fc6)\n",
    "        #block7 : [batch, 4096] => [batch, 1024]\n",
    "        with tf.variable_scope('FC7') as scope:\t\n",
    "            weight=tf.Variable(tf.truncated_normal([4096,4096],dtype=tf.float32,stddev=1e-1))\n",
    "            bias=tf.Variable(tf.constant(1.0,shape=[4096],dtype=tf.float32))\t   \n",
    "            fc7=tf.nn.bias_add(tf.matmul(fc6,weight),bias)\n",
    "            fc7=tf.nn.relu(fc7) \n",
    "            fc7=batch_norm(fc7)\n",
    "        #block8 : [batch, 1024] => [batch, 256]\n",
    "        with tf.variable_scope('FC8') as scope:\t\n",
    "            weight=tf.Variable(tf.truncated_normal([4096,256],dtype=tf.float32,stddev=1e-1))\n",
    "            bias=tf.Variable(tf.constant(1.0,shape=[256],dtype=tf.float32))\t   \n",
    "            fc8=tf.nn.bias_add(tf.matmul(fc7,weight),bias)\n",
    "            fc8=tf.nn.relu(fc8) \n",
    "            fc8=batch_norm(fc8)\n",
    "        #block8 : [batch, 256] => [batch, 2]\n",
    "        with tf.variable_scope('Softmax9') as scope:\t\n",
    "            weight=tf.Variable(tf.truncated_normal([256,1],dtype=tf.float32,stddev=1e-1))\n",
    "            bias=tf.Variable(tf.constant(1.0,shape=[1],dtype=tf.float32))\n",
    "            softmax = tf.nn.bias_add(tf.matmul(fc8,weight),bias)   \n",
    "            softmax = tf.nn.softmax(softmax)  \n",
    "    return softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "f:\\python\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "img = scipy.misc.imread('H:\\\\我的库\\\\Pictures\\\\新建文件夹\\\\1.jpg')\n",
    "resize = scipy.misc.imresize(img, (256, 256))\n",
    "img=resize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'FC_Softmax/Softmax9/Softmax:0' shape=(1, 1) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predition=discrimator(img)\n",
    "predition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Log:0' shape=(1, 1) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_loss_real = tf.log(predition)\n",
    "d_loss_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Log_1:0' shape=(1, 1) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_loss_fake=tf.log(1-predition)\n",
    "d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent' type=NoOp>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(d_loss_real)#学习效率0.5<1\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.]], dtype=float32)]\n",
      "[array([[ 0.]], dtype=float32)]\n",
      "[array([[ 0.]], dtype=float32)]\n",
      "[array([[ 0.]], dtype=float32)]\n",
      "[array([[ 0.]], dtype=float32)]\n",
      "[array([[ 0.]], dtype=float32)]\n",
      "[array([[ 0.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        sess.run(train)\n",
    "        if i % 10 == 0:\n",
    "             print(sess.run([d_loss_real]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
